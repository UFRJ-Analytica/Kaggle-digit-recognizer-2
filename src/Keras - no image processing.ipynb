{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "source": [
    "import pandas              as pd\r\n",
    "import numpy               as np\r\n",
    "import matplotlib.pyplot   as plt\r\n",
    "\r\n",
    "from keras.layers          import Dense\r\n",
    "from keras.models          import Sequential, load_model\r\n",
    "from keras.callbacks       import EarlyStopping\r\n",
    "from keras.metrics         import categorical_crossentropy\r\n",
    "from sklearn.preprocessing import LabelBinarizer, MinMaxScaler"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "source": [
    "# Importing train and test data\r\n",
    "\r\n",
    "train = pd.read_csv('../data/train.zip')\r\n",
    "test = pd.read_csv('../data/test.zip')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "source": [
    "# Separating the target data from the train data\r\n",
    "target = train.label\r\n",
    "train.drop(columns= ['label'], axis = 1, inplace = True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "source": [
    "# Formatting the data\r\n",
    "\r\n",
    "normalizer = MinMaxScaler(feature_range = (0, 1))\r\n",
    "\r\n",
    "# Transform data in binary\r\n",
    "lb = LabelBinarizer()\r\n",
    "\r\n",
    "# Normalize input train and test data\r\n",
    "x_train = normalizer.fit_transform(train)\r\n",
    "x_test = normalizer.fit_transform(test)\r\n",
    "\r\n",
    "y_train = lb.fit_transform(target)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "source": [
    "def new_model(hidden_layers = 1, nodes = 10, patience = 5):\r\n",
    "\r\n",
    "    file_name = f'no_cnn_{hidden_layers}_layer_{nodes}_nodes'\r\n",
    "\r\n",
    "    # Instantiating model\r\n",
    "    model = Sequential()\r\n",
    "\r\n",
    "    # Creating early_stopping\r\n",
    "    early_stopping_monitor = EarlyStopping(patience = patience,\r\n",
    "                                           monitor='val_loss')\r\n",
    "\r\n",
    "    # Adding hidden layers\r\n",
    "    for _ in range (0, hidden_layers):\r\n",
    "        \r\n",
    "        model.add(Dense(nodes, activation = 'relu'))\r\n",
    "\r\n",
    "    # Adding final layer\r\n",
    "    model.add(Dense(10, activation = 'softmax'))\r\n",
    "\r\n",
    "    # Compiling the model\r\n",
    "    model.compile(optimizer = 'adam', \r\n",
    "                  loss = 'categorical_crossentropy',\r\n",
    "                  metrics = ['accuracy'])\r\n",
    "\r\n",
    "    # Fit the model\r\n",
    "    model.fit(x_train, \r\n",
    "              y_train, \r\n",
    "              epochs = 100,  \r\n",
    "              shuffle = True, \r\n",
    "              verbose = 2,\r\n",
    "              callbacks = [early_stopping_monitor],\r\n",
    "              validation_split = 0.3)\r\n",
    "\r\n",
    "    # Creating submission file\r\n",
    "    submission = pd.DataFrame(np.argmax(model.predict(x_test), axis = -1), columns = ['Label'])\r\n",
    "\r\n",
    "    submission.rename_axis('ImageId', inplace=True)\r\n",
    "\r\n",
    "    #Creating Scores Dataframe\r\n",
    "    scores = pd.DataFrame(model.history.history)\r\n",
    "\r\n",
    "    #Saving model\r\n",
    "    model.save(f'../models/{file_name}.h5')\r\n",
    "\r\n",
    "    # Saving submission file\r\n",
    "    submission.to_csv(f'../submission/{file_name}.csv')\r\n",
    "    \r\n",
    "    # Saving Scores\r\n",
    "    scores.to_csv(f'../results/{file_name}.csv')\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "source": [
    "# Best result so far!\r\n",
    "new_model(hidden_layers = 3, nodes = 40)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "919/919 - 2s - loss: 0.4488 - accuracy: 0.8639 - val_loss: 0.2180 - val_accuracy: 0.9348\n",
      "Epoch 2/100\n",
      "919/919 - 1s - loss: 0.1943 - accuracy: 0.9400 - val_loss: 0.2019 - val_accuracy: 0.9396\n",
      "Epoch 3/100\n",
      "919/919 - 1s - loss: 0.1501 - accuracy: 0.9537 - val_loss: 0.1547 - val_accuracy: 0.9525\n",
      "Epoch 4/100\n",
      "919/919 - 1s - loss: 0.1221 - accuracy: 0.9634 - val_loss: 0.1445 - val_accuracy: 0.9562\n",
      "Epoch 5/100\n",
      "919/919 - 1s - loss: 0.1025 - accuracy: 0.9682 - val_loss: 0.1505 - val_accuracy: 0.9562\n",
      "Epoch 6/100\n",
      "919/919 - 1s - loss: 0.0837 - accuracy: 0.9727 - val_loss: 0.1462 - val_accuracy: 0.9589\n",
      "Epoch 7/100\n",
      "919/919 - 1s - loss: 0.0749 - accuracy: 0.9759 - val_loss: 0.1285 - val_accuracy: 0.9637\n",
      "Epoch 8/100\n",
      "919/919 - 1s - loss: 0.0635 - accuracy: 0.9796 - val_loss: 0.1366 - val_accuracy: 0.9635\n",
      "Epoch 9/100\n",
      "919/919 - 1s - loss: 0.0552 - accuracy: 0.9817 - val_loss: 0.1517 - val_accuracy: 0.9597\n",
      "Epoch 10/100\n",
      "919/919 - 1s - loss: 0.0453 - accuracy: 0.9858 - val_loss: 0.1395 - val_accuracy: 0.9647\n",
      "Epoch 11/100\n",
      "919/919 - 1s - loss: 0.0435 - accuracy: 0.9851 - val_loss: 0.1371 - val_accuracy: 0.9645\n",
      "Epoch 12/100\n",
      "919/919 - 1s - loss: 0.0414 - accuracy: 0.9860 - val_loss: 0.1506 - val_accuracy: 0.9637\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "interpreter": {
   "hash": "b36092a86d5950b17c408d584e311ca1413a5f9d8627407d6aab5af74bae2eab"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}